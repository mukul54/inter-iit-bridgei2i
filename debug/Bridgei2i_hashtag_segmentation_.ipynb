{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Bridgei2i-hashtag-segmentation .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "XMfJJg8788RD"
      },
      "source": [
        "# This Kaggle - Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6yUqexP88RN"
      },
      "source": [
        "Extracting all the hashtags from twitter corpus and segmenting the words from them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1KtS9ZH88RO",
        "outputId": "cf544569-f8ce-4490-925a-c4f7ff1dd871"
      },
      "source": [
        "pip install wordsegment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wordsegment\n",
            "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
            "Installing collected packages: wordsegment\n",
            "Successfully installed wordsegment-1.3.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMdvRxVR88RQ"
      },
      "source": [
        "import wordsegment\n",
        "from wordsegment import load, segment,clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNGwlr6w88RR",
        "outputId": "6e26ff7d-ee85-40e5-d660-2c58c7ada352"
      },
      "source": [
        "import re\n",
        "def extract_hash_tags(tweet):\n",
        "    \"extract hashtags from the tweet\"\n",
        "    return set(part[1:] for part in tweet.split() if part.startswith('#'))\n",
        "\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "hashtags =[]\n",
        "\n",
        "punct = string.punctuation\n",
        "exclude_punct = set(punct)\n",
        "exclude_punct_no_hash = set(punct.replace('#',''))\n",
        "\n",
        "## read data from tweet corpus\n",
        "tweets=pd.read_csv('dev_data_tweet.csv')\n",
        "\n",
        "for twt in tweets['Tweet']: \n",
        "    \"clean a tweet and extract hashtags in it\"\n",
        "    non_ASCII_free = (twt.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "    punc_free = ''.join([ch for ch in non_ASCII_free if ch not in exclude_punct_no_hash])\n",
        "    short_word_free = ' '.join(word for word in punc_free.split() )\n",
        "    tags = extract_hash_tags(short_word_free)\n",
        "    for tag in tags:\n",
        "        if(len(tag)>0):\n",
        "            hashtags.append(tag.lower())\n",
        "\n",
        "##unique hashtags        \n",
        "hashtags = list(set(hashtags))\n",
        "\n",
        "print(\"Total unique hashtags found: {0}\".format(len(hashtags)))\n",
        "\n",
        "\n",
        "hashtag_columns = ['hashtag', 'word_segment']\n",
        "data_frame = pd.DataFrame(columns=hashtag_columns)\n",
        "\n",
        "mobile_brands=pd.read_csv('Mobile Brands - Sheet1.csv')\n",
        "mobile_tech=[i.replace(' ','').lower() for i in mobile_brands['Brand']]\n",
        "\n",
        "\n",
        "brand_models=pd.read_csv('model_brands3.csv')\n",
        "mobile_tech1=[i.replace(' ','').lower() for i in brand_models['model']]\n",
        "brand_models['model']=pd.Series(np.array(mobile_tech1))\n",
        "\n",
        "\n",
        "load()   \n",
        "    \n",
        "for hashtag in hashtags:\n",
        "    clean1 = clean(hashtag) \n",
        "    isegment = segment(clean1) \n",
        "    word_segment= list(isegment) \n",
        " \n",
        "\n",
        "\n",
        "    c=0\n",
        "    d={}\n",
        "    for i in brand_models.to_dict(orient='records'):\n",
        "        if re.match(i['model'],hashtag.strip().lower()):\n",
        "            c=c+1\n",
        "            d[i['model']]=len(i['model'])\n",
        "        else:\n",
        "            continue\n",
        "    if c>=1:\n",
        "        key=max(d,key=d.get)\n",
        "        for i in brand_models.to_dict(orient='records'):\n",
        "            if i['model']==key:\n",
        "                word_segment.append(i['brands'])\n",
        "            else:\n",
        "                continue\n",
        "    else:\n",
        "        for i in mobile_tech:\n",
        "            if re.search(i,hashtag.strip().lower()):\n",
        "                word_segment.append(i)\n",
        "            else:\n",
        "                continue\n",
        "        \n",
        "    data_frame = data_frame.append({'hashtag': \"#\" + hashtag, 'word_segment': set(word_segment)}, ignore_index=True)\n",
        "    \n",
        "segmented_Sent=[]\n",
        "for i in data_frame['word_segment']:\n",
        "    segmented_Sent.append(' '.join(i))\n",
        "data_frame['Segmented_Sent']=pd.Series(np.array(segmented_Sent))           \n",
        "            \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique hashtags found: 1048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbrYzquM88RT",
        "outputId": "02b1ba26-722d-4cf4-f7f7-fa85bf9abc51"
      },
      "source": [
        "data_frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hashtag</th>\n",
              "      <th>word_segment</th>\n",
              "      <th>Segmented_Sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#samsungs21ultra</td>\n",
              "      <td>{samsung, ultra, s21}</td>\n",
              "      <td>samsung ultra s21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#wearables</td>\n",
              "      <td>{wearables}</td>\n",
              "      <td>wearables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#samsunga82</td>\n",
              "      <td>{samsung, a82}</td>\n",
              "      <td>samsung a82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#intensivechemotherapy</td>\n",
              "      <td>{intensive, chemotherapy}</td>\n",
              "      <td>intensive chemotherapy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#experiencethefuture</td>\n",
              "      <td>{the, experience, future}</td>\n",
              "      <td>the experience future</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1043</th>\n",
              "      <td>#pnbpathshala</td>\n",
              "      <td>{path, pnb, shala}</td>\n",
              "      <td>path pnb shala</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>#python</td>\n",
              "      <td>{python}</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045</th>\n",
              "      <td>#cm</td>\n",
              "      <td>{cm}</td>\n",
              "      <td>cm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1046</th>\n",
              "      <td>#tigrayna</td>\n",
              "      <td>{tigray, na}</td>\n",
              "      <td>tigray na</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>#chequepickupservice</td>\n",
              "      <td>{service, pickup, cheque}</td>\n",
              "      <td>service pickup cheque</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1048 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     hashtag               word_segment  \\\n",
              "0           #samsungs21ultra      {samsung, ultra, s21}   \n",
              "1                 #wearables                {wearables}   \n",
              "2                #samsunga82             {samsung, a82}   \n",
              "3     #intensivechemotherapy  {intensive, chemotherapy}   \n",
              "4       #experiencethefuture  {the, experience, future}   \n",
              "...                      ...                        ...   \n",
              "1043           #pnbpathshala         {path, pnb, shala}   \n",
              "1044                 #python                   {python}   \n",
              "1045                     #cm                       {cm}   \n",
              "1046               #tigrayna               {tigray, na}   \n",
              "1047    #chequepickupservice  {service, pickup, cheque}   \n",
              "\n",
              "              Segmented_Sent  \n",
              "0          samsung ultra s21  \n",
              "1                  wearables  \n",
              "2                samsung a82  \n",
              "3     intensive chemotherapy  \n",
              "4      the experience future  \n",
              "...                      ...  \n",
              "1043          path pnb shala  \n",
              "1044                  python  \n",
              "1045                      cm  \n",
              "1046               tigray na  \n",
              "1047   service pickup cheque  \n",
              "\n",
              "[1048 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz-H3fmX88RU"
      },
      "source": [
        "data_frame.to_csv('HashtagSegmentation.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHCfGwch88RV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}